{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaia Data Workshop - Heidelberg, November 21-24, 2016 \n",
    "## The Gaia Service at AIP\n",
    "Gal Matijevic // gmatijevic@aip.de\n",
    "## Hands-on Tutorial\n",
    "\n",
    "This notebook will cover the access of the AIP's Gaia service through the UWS (Universal Worker Service) interface. More information about the UWS standard can be found <a href=\"http://www.ivoa.net/documents/UWS/\">here</a>. Another two very useful sources (in pdf format) on the topic are available from <a href=\"http://www.g-vo.org/tutorials/uwsintro.pdf\">here</a> and <a href=\"http://wiki.ivoa.net/internal/IVOA/InterOpMay2016-GWS/uws-client.pdf\">here</a>.\n",
    "\n",
    "In this tutorial we will be using the <a href='https://github.com/aipescience/uws-client'>`uws-client`</a> for python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us import the packages we will need in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import healpy as hp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.rcParams.update(matplotlib.rcParamsDefault)\n",
    "\n",
    "import uws.UWS.client as client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The connection to the database is established very easly through the `Client` object. We need to supply it the url and the user credentials (same as the ones used in the web interface):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://gaia.aip.de/uws/query'\n",
    "username = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cli = client.Client(url, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To list all `PENDING` or `COMPLETED` jobs we can use the `get_job_list()` function (it might take a second or two):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = {'phases': ['PENDING', 'COMPLETED']}\n",
    "job_list = cli.get_job_list(filters)\n",
    "for ref in job_list.job_reference:\n",
    "    print ref.ownerId, ref.creationTime, ref.phase[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar job list can also be shown for other `phases` such as `ABORTED`, `QUEUED` and so on. Jobs can also be listed based on the time of their creation time or their consequtive number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filters = {'last': 2}\n",
    "job_list = cli.get_job_list(filters)\n",
    "for ref in job_list.job_reference:\n",
    "    print ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Controling jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new job to the stack is done with the `new_job()` function. It requires a query and a queue to be passed to it. We wrap both into a dictionary called `parameters`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameters = {'query': 'SELECT ra, `dec` FROM GDR1.tgas_source LIMIT 10',\n",
    "              'queue': 'long'}\n",
    "job = cli.new_job(parameters)\n",
    "print job.phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run it with `run_job()` function. To check the phase of the job we use the `get_job()` to query its state every 10 seconds and see if the phase has changed from `QUEUED`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run = cli.run_job(job.job_id)\n",
    "job = cli.get_job(run.job_id, wait='10', phase='QUEUED')\n",
    "print job.phase[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it is still `EXECUTING` we can re-check the phase with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print job.phase[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the job list in the web interface we will see the submitted job in the list on the left."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fetch the results that the query has generated. We can download the data returned by the query in a few different formats. We will be using the `csv` format as it is easly parsed by the `pandas` package that we will use to read the data into the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if job.phase[0] == 'COMPLETED':\n",
    "    fileurl = str(job.results[0].reference)\n",
    "    cli.connection.download_file(fileurl, username, password,\n",
    "                                 file_name='res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delete the job from the stack so it does not hog our limited user space. We do that using the `delete_job()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deleted = cli.delete_job(job.job_id)\n",
    "print deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operation of submitting a query, downloading a file, converting it to a `pandas` frame, and deleteing a job will be something will re-use again so let us wrap this procedure into a couple of functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def submit_query(client, query, queue):\n",
    "    parameters = {'query': query, 'queue': queue}\n",
    "    job = client.new_job(parameters)\n",
    "    time.sleep(1)\n",
    "    run = client.run_job(job.job_id)\n",
    "    \n",
    "    return run\n",
    "    \n",
    "def get_data(client, run, username, password, wait='10',\n",
    "             filename='res.csv'):\n",
    "    job = client.get_job(run.job_id, wait=wait, phase='QUEUED')\n",
    "    \n",
    "    if job.phase[0] == 'COMPLETED':\n",
    "        fileurl = str(job.results[0].reference)\n",
    "        client.connection.download_file(fileurl, username, password,\n",
    "                                        file_name=filename)\n",
    "        data = pd.read_csv(filename)\n",
    "        success = client.delete_job(job.job_id)\n",
    "        return data\n",
    "    else:\n",
    "        print 'Job in phase %s' % (job.phase[0])\n",
    "        return job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Magnitude histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executing a query and fetching the results can now be done in a couple of lines. A histogram of G magnitudes of TGAS stars can be produced with the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT FLOOR(phot_g_mean_mag * 10) / 10.0 AS gmag,\n",
    "               COUNT(FLOOR(phot_g_mean_mag)) AS count\n",
    "        FROM GDR1.tgas_source\n",
    "        GROUP BY FLOOR(phot_g_mean_mag * 10)\n",
    "        '''\n",
    "run = submit_query(cli, query, queue='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data(cli, run, username, password)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print it out to see we really got what we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(111)\n",
    "ax.step(data['gmag'], data['count'])\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('gmag')\n",
    "ax.set_ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Density plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replicate the TGAS star density diagrams from <a href=\"https://arxiv.org/abs/1609.04303\"> Lindegren et al.</a>, we use the following query. Gaia catalog `source_id` also encodes HEALPix values in nested ordering up to resolution index of 12. To get HEALPix values at lower resolutions we need to divide the `source_id` column with an appropriate factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT hpix, COUNT(hpix) AS number\n",
    "        FROM\n",
    "        ( \n",
    "            SELECT FLOOR(source_id / (POW(2, 35) * POW(4, 12 - 6))) as hpix\n",
    "            FROM GDR1.tgas_source\n",
    "        ) AS hq\n",
    "        GROUP BY hpix\n",
    "        '''\n",
    "run = submit_query(cli, query, queue='long')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data(cli, run, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "density = np.zeros(12 * (2 ** 6) ** 2)\n",
    "for hpix, c in zip(data['hpix'], data['number']):\n",
    "    density[hpix] = c\n",
    "density /= 0.8393  # area of one HEALPix with NSIDE=64\n",
    "    \n",
    "cmap = plt.cm.magma\n",
    "cmap.set_under('w')\n",
    "\n",
    "hp.mollview(density, nest=True, title='Source density [deg^2]', cmap=cmap,\n",
    "            coord='C', norm='log', min=1, max=220)\n",
    "hp.mollview(density, nest=True, title='', cmap=cmap,\n",
    "            coord='CG', norm='log', min=1, max=220, cbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Radial velocities from RAVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Here is a slightly more elaborate example combining the positions of TGAS stars with the radial velocities from RAVE DR5 catalog. It joins two tables that are linked by the `source_id` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "query = '''\n",
    "        SELECT tgas.l AS l, tgas.b AS b, tgas.parallax AS par,\n",
    "               rave.HRV AS rv, rave.logg_K AS logg\n",
    "        FROM GDR1.tgas_source AS tgas, RAVE.RAVE_DR5 AS rave\n",
    "        WHERE rave.ALGO_CONV = 0 AND rave.logg_K > 0\n",
    "        AND tgas.source_id = rave.source_id\n",
    "        LIMIT 50000\n",
    "        '''\n",
    "run = submit_query(cli, query, queue='long')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = get_data(cli, run, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pscatter(ax, x, y, c='k', size=5, cmap=plt.cm.jet):\n",
    "    x = np.remainder(x + 360.0, 360.0)\n",
    "    x[x > 180.0] -= 360.0\n",
    "    sc = ax.scatter(np.radians(-x), np.radians(y), c=c, s=size, lw=0, cmap=cmap)\n",
    "    return sc\n",
    "\n",
    "fig = plt.figure(figsize=(9, 4))\n",
    "ax = plt.subplot(111, projection='aitoff')\n",
    "rv = np.clip(data['rv'], -50, 50)\n",
    "sc = pscatter(ax, data['l'], data['b'], c=rv, size=2)\n",
    "cbar = plt.colorbar(sc)\n",
    "cbar.set_label('HRV [km/s]')\n",
    "ax.set_xticklabels([])\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or in 3D using the TGAS parallax as a distance estimator. In this example we start a simple HTTP server to host the 3D viewer. Afterwards the server has to be stopped using the `kill()` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color = plt.cm.jet((rv + 50.0) / 100.0)\n",
    "data['rc'] = color[:, 0]\n",
    "data['gc'] = color[:, 1]\n",
    "data['bc'] = color[:, 2]\n",
    "data.to_csv('threedviewer/res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Galaxy image credit: R. Hurt (SSC), JPL-Caltech, NASA\n",
    "\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "server = subprocess.Popen(['python', '-m', 'SimpleHTTPServer', '8889'])\n",
    "url_viewer = 'http://localhost:8889/threedviewer'\n",
    "wb = webbrowser.open(url_viewer, new=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "server.kill()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
